name: rag_qa
version: "1.0"
description: "Simple RAG Q&A - load documents, embed, answer via retrieval"
scenario_type: rag_qa
documents_dir: documents/
questions_file: questions.yaml
config:
  embedding_model: text-embedding-3-small
  llm_model: gpt-4o-mini
  chunk_size: 500
  chunk_overlap: 50
  top_k: 3
evaluation:
  profile: default
modes:
  baseline:
    top_k: 3
    max_context_chunks: 3
  capability:
    top_k: 3
    max_context_chunks: 3
